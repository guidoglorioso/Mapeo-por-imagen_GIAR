{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fd1a6e3",
   "metadata": {},
   "source": [
    "# Obtención de Dataset\n",
    "\n",
    "Pasos:\n",
    "1. Colocar 4 arauco en las esquinas.\n",
    "2. Medir y calibrar la cámara.\n",
    "3. Detectar el robot con un 5to arauco distinto.\n",
    "4. Detectar muros/contornos con threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb664d1",
   "metadata": {},
   "source": [
    "# Prueba de detección de Aruco Marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "092a9c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# Cámara:\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# Diccionarios y detectores Aruco Markers:\n",
    "aruco_dict = cv.aruco.getPredefinedDictionary(cv.aruco.DICT_4X4_100)\n",
    "parameters = cv.aruco.DetectorParameters()\n",
    "detector = cv.aruco.ArucoDetector(aruco_dict, parameters)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detección de ArUco\n",
    "    corners, ids, rejected = detector.detectMarkers(frame)\n",
    "\n",
    "    if ids is not None:\n",
    "        cv.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "        for i, corner in enumerate(corners):\n",
    "            c = corner[0]\n",
    "            # Coordenadas del centro\n",
    "            x_corner = int((c[:,0].mean()))\n",
    "            y_center = int((c[:,1].mean()))\n",
    "            cv.circle(frame, (x_corner, y_center), 5, (0,0,255), -1)\n",
    "\n",
    "            print(f\"Marker {ids[i]} en píxeles: ({x_corner},{y_center})\")\n",
    "\n",
    "    cv.imshow(\"Frame\", frame)\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c960f715",
   "metadata": {},
   "source": [
    "# Calibración de Cámara\n",
    "\n",
    "Instrucciones de uso:\n",
    "\n",
    "* Colocar en chess_size las dimensiones del tablero de ajedrez (es decir, la cantida de cuadrados en x e y)\n",
    "* Colocar el tamaño de cada casilla en mm. Como son cuadradas por definición, solo se requiere el largo.\n",
    "\n",
    "\n",
    "*  Se obtienen las variables: ret, mtx, dist, rvecs, tvecs\n",
    "\n",
    "ret: Error de retención. (RMS de error general de la cámara).\n",
    "\n",
    "mtx: Matriz de la cámara. (Matriz de la cámara. 3x3. Indica parámetros propios como el focal lenght).\n",
    "\n",
    "dist: Coeficientes de distorción. **IMPORTANTE** (Array de 5 valores para corrección de la cámara. 3 de distorción radial y 2 de distorción tangencial).\n",
    "\n",
    "rvecs: Vector de rotación. (Matriz de rotación de la imagen. Permite corregir la rotación).\t**IRRELEVANTE**\n",
    "\n",
    "tvecs: Vector de traslación. (Matriz de traslación de la imagen. Permite corregir la posición de la imagen).**IRRELEVANTE**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1f2f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolución usada para calibrar: 2560 x 1440\n",
      "Matriz intrínseca:\n",
      " [[1.99856782e+03 0.00000000e+00 1.29475608e+03]\n",
      " [0.00000000e+00 2.00339165e+03 7.42746877e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "Coeficientes de distorsión:\n",
      " [[-6.28943106e-01  1.04540327e+00  1.36106218e-03  2.96854243e-04\n",
      "  -1.80793651e+00]]\n",
      "Corrigiendo test_images\\WIN_20251014_15_07_53_Pro.jpg\n",
      "test_images\\WIN_20251014_15_07_53_Pro.jpg corregido y guardado en test_iamges/WIN_20251014_15_07_53_Pro.jpg_calib.jpg\n",
      "Corrigiendo test_images\\WIN_20251014_15_07_55_Pro.jpg\n",
      "test_images\\WIN_20251014_15_07_55_Pro.jpg corregido y guardado en test_iamges/WIN_20251014_15_07_55_Pro.jpg_calib.jpg\n",
      "Corrigiendo test_images\\WIN_20251014_15_07_56_Pro.jpg\n",
      "test_images\\WIN_20251014_15_07_56_Pro.jpg corregido y guardado en test_iamges/WIN_20251014_15_07_56_Pro.jpg_calib.jpg\n",
      "Corrigiendo test_images\\WIN_20251014_15_07_58_Pro.jpg\n",
      "test_images\\WIN_20251014_15_07_58_Pro.jpg corregido y guardado en test_iamges/WIN_20251014_15_07_58_Pro.jpg_calib.jpg\n",
      "Corrigiendo test_images\\WIN_20251014_15_07_59_Pro.jpg\n",
      "test_images\\WIN_20251014_15_07_59_Pro.jpg corregido y guardado en test_iamges/WIN_20251014_15_07_59_Pro.jpg_calib.jpg\n",
      "Corrigiendo test_images\\WIN_20251014_15_08_01_Pro.jpg\n",
      "test_images\\WIN_20251014_15_08_01_Pro.jpg corregido y guardado en test_iamges/WIN_20251014_15_08_01_Pro.jpg_calib.jpg\n",
      "Corrigiendo test_images\\WIN_20251014_15_08_04_Pro.jpg\n",
      "test_images\\WIN_20251014_15_08_04_Pro.jpg corregido y guardado en test_iamges/WIN_20251014_15_08_04_Pro.jpg_calib.jpg\n",
      "Corrigiendo test_images\\WIN_20251014_15_08_05_Pro.jpg\n",
      "test_images\\WIN_20251014_15_08_05_Pro.jpg corregido y guardado en test_iamges/WIN_20251014_15_08_05_Pro.jpg_calib.jpg\n",
      "Corrigiendo test_images\\WIN_20251014_15_08_06_Pro.jpg\n",
      "test_images\\WIN_20251014_15_08_06_Pro.jpg corregido y guardado en test_iamges/WIN_20251014_15_08_06_Pro.jpg_calib.jpg\n",
      "Corrigiendo test_images\\WIN_20251014_15_08_07_Pro.jpg\n",
      "test_images\\WIN_20251014_15_08_07_Pro.jpg corregido y guardado en test_iamges/WIN_20251014_15_08_07_Pro.jpg_calib.jpg\n",
      "Corrigiendo test_images\\WIN_20251014_15_08_24_Pro.jpg\n",
      "test_images\\WIN_20251014_15_08_24_Pro.jpg corregido y guardado en test_iamges/WIN_20251014_15_08_24_Pro.jpg_calib.jpg\n",
      "Corrigiendo test_images\\WIN_20251014_15_08_25_Pro.jpg\n",
      "test_images\\WIN_20251014_15_08_25_Pro.jpg corregido y guardado en test_iamges/WIN_20251014_15_08_25_Pro.jpg_calib.jpg\n",
      "Corrigiendo test_images\\WIN_20251014_15_08_26_Pro.jpg\n",
      "test_images\\WIN_20251014_15_08_26_Pro.jpg corregido y guardado en test_iamges/WIN_20251014_15_08_26_Pro.jpg_calib.jpg\n",
      "Corrigiendo test_images\\WIN_20251014_15_08_27_Pro.jpg\n",
      "test_images\\WIN_20251014_15_08_27_Pro.jpg corregido y guardado en test_iamges/WIN_20251014_15_08_27_Pro.jpg_calib.jpg\n",
      "Corrigiendo test_images\\WIN_20251014_15_08_30_Pro.jpg\n",
      "test_images\\WIN_20251014_15_08_30_Pro.jpg corregido y guardado en test_iamges/WIN_20251014_15_08_30_Pro.jpg_calib.jpg\n",
      "Corrigiendo test_images\\WIN_20251014_15_08_32_Pro.jpg\n",
      "test_images\\WIN_20251014_15_08_32_Pro.jpg corregido y guardado en test_iamges/WIN_20251014_15_08_32_Pro.jpg_calib.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "\n",
    "###### VARIABLES ###########################################################\n",
    "chess_size = (9,6)\t\t\t\t\t# Dimensiones de tablero patrón\n",
    "chess_square_lenght = 30.0  \t\t# En mm\n",
    "\n",
    "calib_img_path = 'calibration_images'\n",
    "test_img_path = 'test_images'\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "# Vector de posiciones de esquinas:\n",
    "corner_size = (chess_size[0]-1, chess_size[1]-1)    #Las funciones utilizan las esquinas internas, no la cant de cuadrados\n",
    "objp = np.zeros((corner_size[0]*corner_size[1], 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:corner_size[0],0:corner_size[1]].T.reshape(-1,2)\n",
    "objp *= chess_square_lenght\n",
    "\n",
    "objpoints = [] # puntos 3D en el mundo real\n",
    "imgpoints = [] # puntos 2D en la imagen\n",
    "\n",
    "images = glob.glob(f'{calib_img_path}/*.jpg')\n",
    "\n",
    "if not images:\n",
    "    print(\"No hay imagenes.\")\n",
    "    sys.exit()\n",
    "if len(images) < 10:\n",
    "    print(\"Advertencia. Pocas imágenes. Se recomiendan 10 o más en distintos ángulos\")\n",
    "\n",
    "for fname in images:\n",
    "    # print(f\"Probando foto {fname}\")\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\t\t# Lo pasa a escala de grises para mejorar\n",
    "    ret, corners = cv2.findChessboardCornersSB(gray, corner_size, None)\n",
    "    \n",
    "    if ret == True:\n",
    "        # print(f\"Encontrado en {fname}\")\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv2.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "        cv2.drawChessboardCorners(img, corner_size, corners2, ret)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "if not ret:\n",
    "    print(\"No se encontró nada.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Calibración\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "img = cv2.imread(images[0])\n",
    "calib_res = (img.shape[1], img.shape[0])\n",
    "print(\"Resolución usada para calibrar:\", calib_res[0], \"x\", calib_res[1])\n",
    "\n",
    "print(\"Matriz intrínseca:\\n\", mtx)\n",
    "print(\"Coeficientes de distorsión:\\n\", dist)\n",
    "np.savez(\"calibration_values\", mtx=mtx, dist=dist, calib_res=calib_res)\n",
    "\n",
    "# Verificacion\n",
    "images = glob.glob(f'{test_img_path}/*.jpg')\n",
    "\n",
    "if not images:\n",
    "    print(\"No hay imagenes para verificar.\")\n",
    "    sys.exit()\n",
    "\n",
    "for fname in images:\n",
    "    print(f\"Corrigiendo {fname}\")\n",
    "    img = cv2.imread(fname)\n",
    "    h,  w = img.shape[:2]\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "    # Elimina distorcion\n",
    "    dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    " \n",
    "    # Recorte de la imagen\n",
    "    x, y, w, h = roi\n",
    "    dst = dst[y:y+h, x:x+w]\n",
    "    name = os.path.basename(fname)\n",
    "    cv2.imwrite(f\"{test_img_path}/calibrated_test/{name}_calib.jpg\", dst)\n",
    "    print(f\"{fname} corregido y guardado en test_iamges/{name}_calib.jpg\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c81c38e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "def calib_camara(img_path, chess_dim = (9,6), chess_square_lenght = 30.0, show = True):\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    corner_size = (chess_dim[0]-1, chess_dim[1]-1)    #Las funciones utilizan las esquinas internas, no la cant de cuadrados\n",
    "\n",
    "    objp = np.zeros((corner_size[0]*corner_size[1], 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:corner_size[0],0:corner_size[1]].T.reshape(-1,2)\n",
    "    objp *= chess_square_lenght     # Grilla con todas las posiciones de las esquinas\n",
    "\n",
    "    objpoints = [] # puntos 3D en el mundo real\n",
    "    imgpoints = [] # puntos 2D en la imagen\n",
    "\n",
    "    # Lista de imagenes\n",
    "    images = []\n",
    "    for ext in ('*.jpg', '*.png', '*.jpeg'):\n",
    "        images.extend(glob.glob(os.path.join(img_path, ext)))\n",
    "\n",
    "\n",
    "    if not images:\n",
    "        print(\"No hay imagenes.\")\n",
    "        return None\n",
    "    if len(images) < 10:\n",
    "        print(\"Advertencia. Pocas imágenes. Se recomiendan 10 o más en distintos ángulos\")\n",
    "\n",
    "    for fname in images:\n",
    "        # print(f\"Probando foto {fname}\")\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\t\t# Lo pasa a escala de grises para mejorar\n",
    "        ret, corners = cv2.findChessboardCornersSB(gray, corner_size, None)\n",
    "        \n",
    "        if ret == True:\n",
    "            print(f\"Encontrado en {fname}\")\n",
    "            objpoints.append(objp)\n",
    "            corners2 = cv2.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "            imgpoints.append(corners2)\n",
    "\n",
    "            if show:\n",
    "                cv2.drawChessboardCorners(img, corner_size, corners2, ret)\n",
    "                cv2.imshow('img', img)\n",
    "                cv2.waitKey(500)\n",
    "    if show:\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    if len(objpoints) == 0:\n",
    "        print(\"No se detectaron esquinas en ninguna imagen.\")\n",
    "        return None\n",
    "\n",
    "    # Resolucion utilizada para calibrar\n",
    "    img = cv2.imread(images[0])                  # Nota = usa solo la primer imagen !!! \n",
    "    calib_res = (img.shape[1], img.shape[0])    # calib_res = (WIDHT, HEIGHT) \n",
    "\n",
    "    # Calibración\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    return mtx, dist, rvecs, tvecs, calib_res\n",
    "\n",
    "\n",
    "def save_calib_matrix(file_name, mtx, dist, calib_res):\n",
    "    try:\n",
    "        np.savez(f\"{file_name}\", mtx=mtx, dist=dist, calib_res=calib_res )\n",
    "        print(f\"Matrices guardadas en {file_name}.npz\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al guardar: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def calib_img(img, mtx, dist):\n",
    "    h,  w = img.shape[:2]\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "    # Elimina distorcion\n",
    "    undistorted = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    " \n",
    "    # Recorte de la imagen\n",
    "    x, y, w, h = roi\n",
    "    undistorted = undistorted[y:y+h, x:x+w]\n",
    "    return undistorted, newcameramtx, roi\n",
    "\n",
    "\n",
    "def load_calib_matrix(file):\n",
    "    try:\n",
    "        calib = np.load(f\"{file}.npz\")\n",
    "        mtx, dist, calib_res = calib[\"mtx\"], calib[\"dist\"], calib['calib_res']\n",
    "    except Exception as e:\n",
    "        mtx, dist, calib_res = None, None, None\n",
    "    return mtx, dist, calib_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed95dd8",
   "metadata": {},
   "source": [
    "# Medición de distancia Aruco Marker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b3992",
   "metadata": {},
   "source": [
    "Prueba 1:\n",
    "\n",
    "\n",
    "El marker size es 100mm pero no me devuelve el Z correcto. Me devuelve el doble. Con marker size de 50 funciona bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1959d55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "\n",
    "###### VARIABLES ###########################################################\n",
    "marker_size = 50  # mm\n",
    "\n",
    "#######################################################################################\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "### Creación del diccionario y detector\n",
    "aruco_dict = cv.aruco.getPredefinedDictionary(cv.aruco.DICT_4X4_100)\n",
    "parameters = cv.aruco.DetectorParameters()\n",
    "detector = cv.aruco.ArucoDetector(aruco_dict, parameters)\n",
    "\n",
    "### Carga de la Matriz de calibracion\n",
    "mtx, dist = load_calib_matrix(\"calibration_values\")\n",
    "\n",
    "if mtx is None or dist is None:\n",
    "    print(\"Faltan valores de calibracion\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "### Loop de lectura de video\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detección de ArUco. NOTA: La funcion detecta todos los ArUco en pantalla y los pasa como lista con los ID.\n",
    "    # corners[i][0][corner_num] -> (xi, yi)\n",
    "    # ids[i] -> id del marker i\n",
    "    corners, ids, _ = detector.detectMarkers(frame)\n",
    "\n",
    "    if ids is not None:\n",
    "        # tvecs[i][0] -> (x,y,z)\n",
    "        rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, marker_size, mtx, dist)\n",
    "\n",
    "        cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "        for i in range(len(ids)):\n",
    "            cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "            # Dibujar ejes\n",
    "            cv2.drawFrameAxes(frame, mtx, dist, rvecs[i], tvecs[i], 50)\n",
    "            \n",
    "            # Mostrar distancia Z (en mm)\n",
    "            x, y, z = tvecs[i][0]\n",
    "\n",
    "            print(f\"marcador {ids[i]} en (x:{x:.2f},y:{x:.2f},z:{z:.2f})\")\n",
    "\n",
    "            x_corner = int(corners[i][0][3][0])\n",
    "            y_corner = int(corners[i][0][3][1])\n",
    "            \n",
    "            \n",
    "            #print(f\"Marker {ids[i]} a {distancia:.1f} mm de la cámara\")\n",
    "\n",
    "            cv2.putText(frame, f\"Z: {z:.1f}\",(x_corner, y_corner - 10),                       \n",
    "                       cv.FONT_HERSHEY_SIMPLEX, \n",
    "                       0.8, \n",
    "                       (255, 0, 0), \n",
    "                       2, \n",
    "                       cv.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb0feb",
   "metadata": {},
   "source": [
    "Prueba 2: (El código fue sacado del siguiente [link](https://visionbrick.com/measuring-depth-from-a-single-camera-using-aruco-markers-in-opencv/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5256fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\"\"\" \n",
    "load your camera’s intrinsic matrix and distortion coefficients from a YAML file\n",
    "- camera_matrix is the 3×3 intrinsic parameters matrix.\n",
    "- dist_coeffs holds lens distortion parameters.\n",
    "- marker_length is the side length of the ArUco marker in meters.\n",
    "\"\"\"\n",
    "camera_matrix, dist_coeffs = load_calib_matrix(\"calibration_values\")\n",
    "marker_length = 100  # mm\n",
    " \n",
    "\"\"\"\n",
    "DICT_4X4_50 is a predefined dictionary of ArUco markers.\n",
    "4x4 markers with 50 unique IDs.(16 bits per marker)\n",
    "parameters are the default detection parameters.\n",
    "\"\"\"\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_100)\n",
    "parameters = cv2.aruco.DetectorParameters()\n",
    " \n",
    "# create a detector instance with default parameters.\n",
    "detector = cv2.aruco.ArucoDetector(aruco_dict, parameters)\n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "num=0\n",
    " \n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    " \n",
    "    # Detect markers in the frame with detectMarkers method\n",
    "    corners, ids, _ = detector.detectMarkers(frame)\n",
    "    \"\"\"\n",
    "    Example output of corners:\n",
    "    (array([[[ 15., 339.],\n",
    "        [ 91., 334.],\n",
    "        [ 98., 404.],\n",
    "        [ 19., 414.]]], dtype=float32),)\n",
    "    \"\"\"\n",
    " \n",
    "    if ids is not None and len(ids) > 0:\n",
    "        cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    " \n",
    "        # Define the 3D coordinates of the marker corners in the marker's coordinate system\n",
    "        obj_points = np.array([\n",
    "            [-marker_length / 2,  marker_length / 2, 0],\n",
    "            [ marker_length / 2,  marker_length / 2, 0],\n",
    "            [ marker_length / 2, -marker_length / 2, 0],\n",
    "            [-marker_length / 2, -marker_length / 2, 0]\n",
    "        ], dtype=np.float32)\n",
    " \n",
    "         \n",
    "        for marker_corners in corners:\n",
    "            image_points = marker_corners[0].astype(np.float32)\n",
    " \n",
    "            \"\"\"\n",
    "            solvePnP estimates the pose of a 3D object given its 3D points and corresponding 2D image points.\n",
    "            It returns the rotation vector (rvec) and translation vector (tvec).\n",
    "            \"\"\"\n",
    "            retval, rvec, tvec = cv2.solvePnP(obj_points, image_points, camera_matrix, dist_coeffs)\n",
    "             \n",
    "            if retval:\n",
    "                # Draw the axis on the frame\n",
    "                cv2.drawFrameAxes(frame, camera_matrix, dist_coeffs, rvec, tvec, 0.03)\n",
    "                 \n",
    "                # Extract the translation vector and calculate the distance\n",
    "                x, y, z = tvec.flatten()\n",
    "                distance = np.linalg.norm(tvec)\n",
    "                \n",
    "                # Print to terminal\n",
    "                print(f\"X={x:.3f} m, Y={y:.3f} m, Z(depth)={z:.3f} m, Distance={distance:.3f} m\")\n",
    "                \n",
    "                # Display on frame with different colors\n",
    "                org = (20, 40)  \n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                font_scale = 0.7\n",
    "                thickness = 2\n",
    "                cv2.putText(frame, f\"X={x:.3f} mm\", (org[0], org[1]), font, font_scale, (0, 255, 0), thickness, cv2.LINE_AA)\n",
    "                cv2.putText(frame, f\"Y={y:.3f} mm\", (org[0], org[1]+30), font, font_scale, (255, 0, 0), thickness, cv2.LINE_AA)\n",
    "                cv2.putText(frame, f\"Depth={z:.3f} mm\", (org[0], org[1]+60), font, font_scale, (0, 0, 255), thickness, cv2.LINE_AA)\n",
    "                cv2.putText(frame, f\"Dist={distance:.3f} mm\", (org[0], org[1]+90), font, font_scale, (0, 255, 255), thickness, cv2.LINE_AA)\n",
    " \n",
    "    # Display the frame with detected markers and pose estimatio\n",
    "    cv2.imshow('ArUco Pose Estimation', frame)\n",
    "      \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6984679",
   "metadata": {},
   "source": [
    "# Rectificación de la foto\n",
    "\n",
    "Utilizando 4 ArUco Markers se busca que el plano quede totalmente perpendicular. Este código debería ajustar eso y ver \"desde arriba\" al plano.\n",
    "\n",
    "Se le conoce como **Homografía**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf188204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n",
      "Imagen alineada correctamente.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "## Variables:\n",
    "calib_value_file = \"calibration_values\"\n",
    "\n",
    "corner_ids = [15, 15, 15, 15]\n",
    "\n",
    "plane_size = (360, 460)     # En mm\n",
    "pixels_per_mm = 2           # Resolution\n",
    "\n",
    "\n",
    "# Cálculo de puntos de esquinas (ejemplo: ([0 0], [0 100], [24 0], [24 100]) mm)\n",
    "image_size = (plane_size[0]*pixels_per_mm,\n",
    "              plane_size[1]*pixels_per_mm) \n",
    "\n",
    "real_points = np.array([\n",
    "                [0, 0],                             # arriba izq\n",
    "                [image_size[0]-1, 0],               # arriba der\n",
    "                [image_size[0]-1, image_size[1]-1], # abajo der\n",
    "                [0, image_size[1]-1]                # abajo izq\n",
    "            ], dtype=np.float32)\n",
    "\n",
    "\n",
    "## Código:\n",
    "mtx, dist, calib_res = load_calib_matrix(calib_value_file)\n",
    "calib_res = tuple(calib_res)\n",
    "\n",
    "if mtx is None or dist is None:\n",
    "    print(\"No hay matriz intrinseca y/o coeficientes de distorsion\")\n",
    "    sys.exit(1)\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, calib_res[0])\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, calib_res[1])\n",
    "\n",
    "# Detector de ArUco\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_100)\n",
    "parameters = cv2.aruco.DetectorParameters()\n",
    "detector = cv2.aruco.ArucoDetector(aruco_dict, parameters)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read() # Solo para el caso de video. Omitir con fotos.\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Corrección y detección de ArUco Marker:\n",
    "    calib_frame, _, _ = calib_img(frame, mtx, dist)\n",
    "\n",
    "    # corners[i][0][corner_num] -> (xi, yi)\n",
    "    # ids[i] -> id del marker i\n",
    "    corners, ids, _ = detector.detectMarkers(calib_frame)\n",
    "\n",
    "    if ids is not None:\n",
    "        calib_frame = cv2.aruco.drawDetectedMarkers(calib_frame, corners, ids)       # Solo visual\n",
    "\n",
    "        # Busqueda de corners:\n",
    "        ids = ids.flatten()\n",
    "        detected_centers = []\n",
    "\n",
    "        for i, marker_id in enumerate(ids):\n",
    "            # Obtengo centros solo de los corners ID:\n",
    "            if marker_id in corner_ids:\n",
    "                c = corners[i][0]\n",
    "                center = c.mean(axis=0)\n",
    "                detected_centers.append(center)\n",
    "                cv2.circle(frame, (int(center[0]), int(center[1])), 5, (0,0,255), -1)  # Solo visual\n",
    "\n",
    "        if len(detected_centers) == 4:\n",
    "            detected_centers = np.array(detected_centers, dtype=np.float32)\n",
    "\n",
    "            s = detected_centers.sum(axis=1)\n",
    "            diff = np.diff(detected_centers, axis=1)\n",
    "\n",
    "            top_left = detected_centers[np.argmin(s)]\n",
    "            bottom_right = detected_centers[np.argmax(s)]\n",
    "            top_right = detected_centers[np.argmin(diff)]\n",
    "            bottom_left = detected_centers[np.argmax(diff)]\n",
    "\n",
    "            detected_points = np.array([top_left, top_right, bottom_right, bottom_left], dtype=np.float32)\n",
    "\n",
    "            # Corrección de la imagen: \n",
    "            H, _ = cv2.findHomography(detected_points, real_points)\n",
    "            aligned = cv2.warpPerspective(calib_frame, H, image_size)\n",
    "            print(\"Imagen alineada correctamente.\")\n",
    "            cv2.imshow(\"Vista Alineada\", aligned)\n",
    "\n",
    "    cv2.imshow(\"Camara\", calib_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "213b64c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def warpImage(calib_value_file, images_path, corner_ids, plane_size, pixels_per_mm):\n",
    "    '''\n",
    "    Realiza Homografía con 4 esquinas ArUco.\n",
    "    calib_value_file: Nombre de archivo (sin extensión) de las matrices de distorsión.\n",
    "    images_path: path a carpeta de imágenes que van a realizar el path.\n",
    "    corner_ids: IDs de ArUco a identificar como esquinas.\n",
    "    plane_size: Tamaño del plano de 4 esquinas.\n",
    "    pixels_per_mm: Resolución pixeles --> mm.\n",
    "    '''\n",
    "    # Cálculo de puntos de esquinas (ejemplo: ([0 0], [0 100], [24 0], [24 100]) mm)\n",
    "    image_size = (plane_size[0]*pixels_per_mm,\n",
    "                plane_size[1]*pixels_per_mm) \n",
    "\n",
    "    real_points = np.array([\n",
    "                    [0, 0],                             # arriba izq\n",
    "                    [image_size[0]-1, 0],               # arriba der\n",
    "                    [image_size[0]-1, image_size[1]-1], # abajo der\n",
    "                    [0, image_size[1]-1]                # abajo izq\n",
    "                ], dtype=np.float32)\n",
    "\n",
    "    # Detector de ArUco\n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_100)\n",
    "    parameters = cv2.aruco.DetectorParameters()\n",
    "    detector = cv2.aruco.ArucoDetector(aruco_dict, parameters)\n",
    "\n",
    "\n",
    "    ## Dir de Salida\n",
    "    out_path = os.path.join(images_path, \"warped\")\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "    ## Código:\n",
    "    mtx, dist, calib_res = load_calib_matrix(calib_value_file)\n",
    "    calib_res = tuple(calib_res)\n",
    "\n",
    "    if mtx is None or dist is None:\n",
    "        print(\"No hay matriz intrinseca y/o coeficientes de distorsion\")\n",
    "        return\n",
    "\n",
    "    images = get_image_paths(images_path)\n",
    "\n",
    "    for fname in images:\n",
    "        image = cv2.imread(fname)\n",
    "\n",
    "        if (image.shape[1], image.shape[0]) != calib_res:\n",
    "            print(\"WARNING: Resolucion de imagen diferente a la de calibracion\\n\")\n",
    "\n",
    "        # Corrección y detección de ArUco Marker:\n",
    "        calib_frame, _, _ = calib_img(image, mtx, dist)\n",
    "        # corners[i][0][corner_num] -> (xi, yi)\n",
    "        # ids[i] -> id del marker i\n",
    "        \n",
    "        gray_calib_img = cv2.cvtColor(calib_frame, cv2.COLOR_BGR2GRAY)\n",
    "        corners, ids, _ = detector.detectMarkers(gray_calib_img)\n",
    "        frame_markers = calib_frame.copy()\n",
    "        cv2.aruco.drawDetectedMarkers(frame_markers, corners, ids)\n",
    "        cv2.imshow(\"Aruco detectados\", frame_markers)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "\n",
    "        corner_coords = get_corners(corner_ids, corners, ids)\n",
    "        if corner_coords is None or len(corner_coords) != 4:\n",
    "            print('no hay coordenadas')\n",
    "            continue\n",
    "\n",
    "        # Corrección de la imagen: \n",
    "        H, _ = cv2.findHomography(corner_coords, real_points)\n",
    "        aligned = cv2.warpPerspective(calib_frame, H, image_size)\n",
    "\n",
    "        outname = os.path.join(out_path, os.path.basename(fname))\n",
    "        cv2.imwrite(outname, aligned)\n",
    "        print(f\"Imagen {fname} alineada correctamente.\\nGuardada en: {out_path}\")\n",
    "\n",
    "def get_corners(corner_ids, corners, ids):\n",
    "    '''\n",
    "    Devuelve un vector de 4 posiciones con los centros de cada esquina. \n",
    "    El resultado está ordenado [TOP LEFT, TOP RIGHT, BOTTOM RIGHT, BOTTOM LEFT]\n",
    "    corner_ids: Id's a utilizar como esquina.\n",
    "    corners: Vectos de esquinas de todos los ArUco obtenidos.\n",
    "    ids: Id de cada ArUco enviado en corners.\n",
    "    '''\n",
    "    detected_centers = []\n",
    "    corner_coords = []\n",
    "    if ids is not None:\n",
    "        # Busqueda de corners:\n",
    "        ids = ids.flatten()\n",
    "\n",
    "        for i, marker_id in enumerate(ids):\n",
    "            # Obtengo centros solo de los corners ID:\n",
    "            if marker_id in corner_ids:\n",
    "                c = corners[i][0]\n",
    "                center = c.mean(axis=0)\n",
    "                detected_centers.append(center)\n",
    "\n",
    "        if len(detected_centers) == 4:\n",
    "            detected_centers = np.array(detected_centers, dtype=np.float32)\n",
    "\n",
    "            s = detected_centers.sum(axis=1)\n",
    "            diff = np.diff(detected_centers, axis=1)\n",
    "\n",
    "            top_left = detected_centers[np.argmin(s)]\n",
    "            bottom_right = detected_centers[np.argmax(s)]\n",
    "            top_right = detected_centers[np.argmin(diff)]\n",
    "            bottom_left = detected_centers[np.argmax(diff)]\n",
    "\n",
    "            corner_coords = np.array([top_left, top_right, bottom_right, bottom_left], dtype=np.float32)\n",
    "\n",
    "    return corner_coords\n",
    "        \n",
    "def get_image_paths(image_path):\n",
    "    '''\n",
    "    Devuelve una lista con todas las imágenes en una carpeta específica.\n",
    "    image_path: Path de carpeta donde se buscan imágenes.\n",
    "    '''\n",
    "    images = []\n",
    "    for ext in ('*.jpg', '*.png', '*.jpeg'):\n",
    "        images.extend(glob.glob(os.path.join(image_path, ext)))\n",
    "    \n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01608b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen warp_test\\WIN_20251015_16_31_27_Pro.jpg alineada correctamente.\n",
      "Guardada en: warp_test\\warped\n",
      "Imagen warp_test\\WIN_20251015_16_31_28_Pro.jpg alineada correctamente.\n",
      "Guardada en: warp_test\\warped\n",
      "Imagen warp_test\\WIN_20251015_16_31_29_Pro.jpg alineada correctamente.\n",
      "Guardada en: warp_test\\warped\n",
      "no hay coordenadas\n",
      "no hay coordenadas\n",
      "Imagen warp_test\\WIN_20251015_16_31_44_Pro.jpg alineada correctamente.\n",
      "Guardada en: warp_test\\warped\n",
      "no hay coordenadas\n"
     ]
    }
   ],
   "source": [
    "## Variables:\n",
    "calib_value_file = \"calibration_values\"\n",
    "\n",
    "corner_ids = [15, 15, 15, 15]\n",
    "\n",
    "plane_size = (595, 420)     # En mm\n",
    "pixels_per_mm = 2           # Resolution\n",
    "\n",
    "warpImage(calib_value_file, 'warp_test', corner_ids, plane_size, pixels_per_mm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77931743",
   "metadata": {},
   "outputs": [],
   "source": [
    "### estimatePoseBoard para pasar a imagen sin distorsion\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Hacer threshold de color:\n",
    "### -Pasar imagen a RGB2HSV\n",
    "### -bitwise_or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bf52a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorDetect(images_path, color_range, show=True):\n",
    "    \"\"\"\n",
    "    Detecta regiones de un color específico en todas las imágenes dentro de 'images_path/warped'\n",
    "    y guarda los resultados en 'images_path/color'.\n",
    "\n",
    "    Parameters:\n",
    "        images_path (str): Carpeta base donde están las imágenes originales.\n",
    "        color_range (tuple): (lower_HSV, upper_HSV) con los límites del color a detectar.\n",
    "        show (bool): Muestra los resultados visualmente (por defecto True).\n",
    "    \"\"\"\n",
    "\n",
    "    warped_dir = os.path.join(images_path, \"warped\")\n",
    "    color_dir = os.path.join(images_path, \"color\")\n",
    "    os.makedirs(color_dir, exist_ok=True)\n",
    "\n",
    "    images = []\n",
    "    for ext in ('*.jpg', '*.png', '*.jpeg'):\n",
    "        images.extend(glob.glob(os.path.join(warped_dir, ext)))\n",
    "\n",
    "    if not images:\n",
    "        print(\"No hay imágenes en la carpeta 'warped'.\")\n",
    "        return\n",
    "\n",
    "    lower, upper = color_range\n",
    "\n",
    "    for fname in images:\n",
    "        print(f\"Procesando {fname}\")\n",
    "        image = cv2.imread(fname)\n",
    "\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.inRange(hsv, lower, upper)\n",
    "\n",
    "        # Limpieza de ruido\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # resultado a color\n",
    "        result = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "        outname_mask = os.path.join(color_dir, os.path.basename(fname).replace(\".\", \"_mask.\"))\n",
    "        outname_result = os.path.join(color_dir, os.path.basename(fname).replace(\".\", \"_color.\"))\n",
    "\n",
    "        cv2.imwrite(outname_mask, mask)\n",
    "        cv2.imwrite(outname_result, result)\n",
    "        print(f\"Guardado: {outname_mask} y {outname_result}\")\n",
    "\n",
    "        if show:\n",
    "            cv2.imshow(\"Original\", image)\n",
    "            cv2.imshow(\"Detección\", result)\n",
    "            key = cv2.waitKey(500)\n",
    "            if key == 27:  # ESC para salir\n",
    "                break\n",
    "\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2a90204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando warp_test\\warped\\WIN_20251015_16_31_27_Pro.jpg\n",
      "Guardado: warp_test\\color\\WIN_20251015_16_31_27_Pro_mask.jpg y warp_test\\color\\WIN_20251015_16_31_27_Pro_color.jpg\n",
      "Procesando warp_test\\warped\\WIN_20251015_16_31_28_Pro.jpg\n",
      "Guardado: warp_test\\color\\WIN_20251015_16_31_28_Pro_mask.jpg y warp_test\\color\\WIN_20251015_16_31_28_Pro_color.jpg\n",
      "Procesando warp_test\\warped\\WIN_20251015_16_31_29_Pro.jpg\n",
      "Guardado: warp_test\\color\\WIN_20251015_16_31_29_Pro_mask.jpg y warp_test\\color\\WIN_20251015_16_31_29_Pro_color.jpg\n",
      "Procesando warp_test\\warped\\WIN_20251015_16_31_44_Pro.jpg\n",
      "Guardado: warp_test\\color\\WIN_20251015_16_31_44_Pro_mask.jpg y warp_test\\color\\WIN_20251015_16_31_44_Pro_color.jpg\n"
     ]
    }
   ],
   "source": [
    "lower_blue = (100, 150, 50)\n",
    "upper_blue = (130, 255, 255)\n",
    "\n",
    "colorDetect(\"warp_test\", (lower_blue, upper_blue))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
